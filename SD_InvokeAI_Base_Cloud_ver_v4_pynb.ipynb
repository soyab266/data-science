{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/soyab266/data-science/blob/master/SD_InvokeAI_Base_Cloud_ver_v4_pynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anqY-GmKTL8V"
      },
      "source": [
        "# **StableDiffusion InvokeAI Base Cloud version**\n",
        "\n",
        "\n",
        "![youtube.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAMAAAAoLQ9TAAAAJ1BMVEVHcEz/AAD/AAD/AAD/AAD/AAD/AAD/AAD/AAD/////mJj/wcH/jY3aUCqcAAAACHRSTlMA8czbELSvDrGIfzkAAABCSURBVBiVY2AgA7CwMTMycgABIyMzGztQgIkDCTABBThQAEyAixtNgIeTkwu/AIYWZEMxrGVhZWaE8BiZWVnI8RoAJWEEDt2WmW4AAAAASUVORK5CYII=) **[YouTube](https://www.youtube.com/@marat_ai)** | ![youtube.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAMAAAAoLQ9TAAAA0lBMVEVHcEwASXEAVIIASXEAW40AW40AW40AW40AW40AW40ASXEARmwASXEAPV4ATnkAQGQAUoAAUn8AWowAQmYANFEANVIAQWUASXEAUHwAQmcAWowASXEAUX0AW40ASXGPscSPr8B/pLh/rcYMUXdJfZkDS3KlwtIqdqBWhqB9q8WZtsY/dpQzbY1Xh6GUs8MAWowAUHwAVoUqdp8AVIJ9pLkqZ4h9orelvsyJq70AWosAWYoATniNrb+kwM8ATHZ+oreBpbnF1t8DS3PI1+BbiaNbiqT25ex8AAAAHXRSTlMAmzOe3PvEmp3+3Ar+CjM0M/v7CgoKCsUzNNz7+yV3I4EAAACzSURBVBjTTY/XEoJADEUjbUEBezdrASxg7737/79kdmEcz9PeM5NsLgCRY5qua0yBmKJpocQyMyJXDPxhCGPiHyZAzcJBvy3pL9FSgCGOhlwyXC+QgYbYO/si+/suXzVAJ+Hdyfg3r8t5Kxbj12TyGAvRlCPR9Pl5B9OIRFouDQOxIwi3nKfApW8vHcluw+26POx45QkqXerQ6YdTnKtlUcahcrM5RVstJX1dphXy6VRWvL8EBRlO0i9n9wAAAABJRU5ErkJggg==) **[sdg.marat@gmail.com]** |\n",
        "![pp.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAtUlEQVQ4jWNgYGBYCcSrgLibARNwAnEUEE8G4gVAXAvEOuiK/gHxfyC+gCbuAMSPoXLIGKR+NhBz4DPACoh/YNGMjDcAMSM2A5iB+DoBzTAcgc0AByI1g/BebAYUkWDAe2wGlJFgwBdsBviTYMBpbAZwAfFLIg0owGYACEQRofk8AzQt4EpI2UD8C4fmk0AsBVOIywAQUGaAJPEjQHwJiNcBcTQDJK3AAT4DiAIDbwC+7EwQAADZX5HHysvpxQAAAABJRU5ErkJggg==) [Other Notebooks](https://www.patreon.com/marat_ai)\n",
        "\n",
        "_You don't need additional Google Drive storage because uploaded models are not stored on your Google Drive. After the session ends, all data will be deleted._"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "JQ5qVdNPFqYJ"
      },
      "outputs": [],
      "source": [
        "#@markdown # **STEP 1**\n",
        "#@markdown ## Requirements\n",
        "#@markdown It might finished with error but is not the error, just execute the next cell\n",
        "\n",
        "from IPython.display import clear_output\n",
        "\n",
        "%cd /content\n",
        "!git clone https://github.com/rocketpal/InvokeAI\n",
        "!pip install -q dependency_injector diffusers einops eventlet facexlib flask_cors flask_socketio flaskwebgui getpass_asterisk huggingface-hub\n",
        "!pip install -q kornia omegaconf pudb pyreadline3 pytorch-lightning realesrgan streamlit taming-transformers-rom1504 test-tube torch-fidelity\n",
        "!pip install -q torchmetrics transformers picklescan\n",
        "!pip install -q pillow xformers==0.0.22 triton==2.0.0 -U\n",
        "clear_output()\n",
        "\n",
        "!pip install -q git+https://github.com/invoke-ai/GFPGAN@basicsr-1.4.2#egg=gfpgan\n",
        "!pip install -q git+https://github.com/openai/CLIP.git@main#egg=clip\n",
        "!pip install -q git+https://github.com/Birch-san/k-diffusion.git@mps#egg=k-diffusion\n",
        "!pip install -q git+https://github.com/invoke-ai/clipseg.git@relaxed-python-requirement#egg=clipseg\n",
        "!pip install -q git+https://github.com/invoke-ai/PyPatchMatch@0.1.4#egg=pypatchmatch\n",
        "%cd /content/InvokeAI/\n",
        "!pip install -q -e .\n",
        "clear_output()\n",
        "\n",
        "\n",
        "!wget https://raw.githubusercontent.com/rocketpal/InvokeAI-colab/main/INITIAL_MODELS.yaml -O /content/InvokeAI/invokeai/configs/INITIAL_MODELS.yaml\n",
        "clear_output()\n",
        "\n",
        "print('\u001b[1;32mDone!')\n",
        "\n",
        "!pip install python-socketio==5.9.0\n",
        "clear_output()\n",
        "\n",
        "#exit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBZ0AbI-U_zk",
        "outputId": "04e8292a-a9dd-4330-eec5-783c604812e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;32mDone! All models downloaded successfully ðŸ™ƒ\n"
          ]
        }
      ],
      "source": [
        "#@markdown # **STEP 2**\n",
        "#@markdown ## Downloading models _(checkpoints, LoRAs, ControlNets, etc.)_\n",
        "#@markdown To configure the downloading of models, edit this file:\n",
        "#@markdown _/content/InvokeAI/invokeai/configs/INITIAL_MODELS.yaml_\n",
        "\n",
        "#@markdown P.S. It's fully explained in the tutorial.\n",
        "from IPython.display import clear_output\n",
        "\n",
        "%cd /content/InvokeAI/\n",
        "!python /content/InvokeAI/scripts/invokeai-model-install.py --root_dir /content/db --yes\n",
        "\n",
        "clear_output()\n",
        "print('\u001b[1;32mDone! All models downloaded successfully ðŸ™ƒ')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AuFwU5t8POIS",
        "outputId": "fb2c2e02-ecab-482b-e9ce-88c02f3b2e56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " [1;32m Model just loaded! ðŸš€\n"
          ]
        }
      ],
      "source": [
        "#@markdown ### Load Model (option2)\n",
        "model_link = \"https://civitai.com/api/download/models/128713?type=Model&format=SafeTensor&size=pruned&fp=fp16\" # @param {type:\"string\"}\n",
        "\n",
        "!wget -O /content/db/models/sd-1/main/model.safetensors \"{model_link}\"\n",
        "\n",
        "clear_output()\n",
        "print(' [1;32m Model just loaded! ðŸš€')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWoTrZLRP5zh",
        "outputId": "50088995-cce1-41fd-ddeb-00966d342662"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/InvokeAI\n",
            "Warning: Permanently added 'remote.moe' (ED25519) to the list of known hosts.\n",
            "\u001b[1mhttp\u001b[0m (80)\n",
            "http://66bbar4aijkrmczcci4ahdgci2heyuuujoxudognu27zjjoaemcq.remote.moe/\n",
            "\n",
            "$\n",
            " \n",
            "2023-11-05 07:52:28.631773: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-05 07:52:28.631829: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-05 07:52:28.631878: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-05 07:52:30.972784: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional_tensor.py:5: UserWarning: The torchvision.transforms.functional_tensor module is deprecated in 0.15 and will be **removed in 0.17**. Please don't rely on it. You probably just need to use APIs in torchvision.transforms.functional or in torchvision.transforms.v2.functional.\n",
            "  warnings.warn(\n",
            ">> patchmatch.patch_match: INFO - Compiling and loading c extensions from \"/usr/local/lib/python3.10/dist-packages/patchmatch\".\n",
            ">> patchmatch.patch_match: WARNING - patchmatch failed to load or compile.\n",
            ">> patchmatch.patch_match: WARNING - Refer to https://github.com/invoke-ai/InvokeAI/blob/main/docs/installation/INSTALL_PATCHMATCH.md for installation instructions.\n",
            "\u001b[38;20m[2023-11-05 07:52:40,710]::[InvokeAI]::INFO --> Patchmatch not loaded (nonfatal)\u001b[0m\n",
            "\u001b[38;20m[2023-11-05 07:52:42,012]::[uvicorn.error]::INFO --> Started server process [4285]\u001b[0m\n",
            "\u001b[38;20m[2023-11-05 07:52:42,013]::[uvicorn.error]::INFO --> Waiting for application startup.\u001b[0m\n",
            "\u001b[38;20m[2023-11-05 07:52:42,013]::[InvokeAI]::INFO --> InvokeAI version 3.1.0\u001b[0m\n",
            "\u001b[38;20m[2023-11-05 07:52:42,014]::[InvokeAI]::INFO --> Root directory = /content/db\u001b[0m\n",
            "\u001b[38;20m[2023-11-05 07:52:42,258]::[InvokeAI]::INFO --> GPU device = cuda Tesla T4\u001b[0m\n",
            "\u001b[38;20m[2023-11-05 07:52:42,263]::[InvokeAI]::INFO --> Scanning /content/db/models for new models\u001b[0m\n",
            "\u001b[38;20m[2023-11-05 07:52:42,966]::[InvokeAI]::INFO --> Scanned 6 files and directories, imported 0 models\u001b[0m\n",
            "\u001b[38;20m[2023-11-05 07:52:42,971]::[InvokeAI]::INFO --> Model manager service initialized\u001b[0m\n",
            "\u001b[38;20m[2023-11-05 07:52:43,006]::[uvicorn.error]::INFO --> Application startup complete.\u001b[0m\n",
            "\u001b[38;20m[2023-11-05 07:52:43,006]::[uvicorn.error]::INFO --> Uvicorn running on http://127.0.0.1:9090 (Press CTRL+C to quit)\u001b[0m\n",
            "\u001b[38;20m[2023-11-05 08:06:32,244]::[uvicorn.access]::INFO --> 37.151.215.77:0 - \"GET / HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2023-11-05 08:06:32,467]::[uvicorn.access]::INFO --> 37.151.215.77:0 - \"GET /assets/index-08cda350.js HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2023-11-05 08:06:38,762]::[uvicorn.access]::INFO --> 37.151.215.77:0 - \"GET /locales/en.json HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2023-11-05 08:06:38,770]::[uvicorn.access]::INFO --> 37.151.215.77:0 - \"GET /assets/ThemeLocaleProvider-707a230a.js HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2023-11-05 08:06:38,856]::[uvicorn.access]::INFO --> 37.151.215.77:0 - \"GET /assets/ThemeLocaleProvider-90f0fcd3.css HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2023-11-05 08:06:38,856]::[uvicorn.access]::INFO --> 37.151.215.77:0 - \"GET /assets/menu-3d10c968.js HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2023-11-05 08:06:39,258]::[uvicorn.access]::INFO --> 37.151.215.77:0 - \"GET /assets/logo-13003d72.png HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2023-11-05 08:06:39,431]::[uvicorn.access]::INFO --> 37.151.215.77:0 - \"GET /assets/App-6125620a.css HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2023-11-05 08:06:39,431]::[uvicorn.access]::INFO --> 37.151.215.77:0 - \"GET /assets/App-78495256.js HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2023-11-05 08:06:39,660]::[uvicorn.access]::INFO --> 37.151.215.77:0 - \"GET /assets/favicon-0d253ced.ico HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2023-11-05 08:06:41,281]::[uvicorn.access]::INFO --> 37.151.215.77:0 - \"GET /socket.io/?EIO=4&transport=polling&t=OkUXGe9 HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2023-11-05 08:06:41,328]::[uvicorn.access]::INFO --> 37.151.215.77:0 - \"GET /api/v1/models/?model_type=embedding HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2023-11-05 08:06:41,397]::[uvicorn.access]::INFO --> 37.151.215.77:0 - \"GET /api/v1/app/version HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2023-11-05 08:06:50,254]::[InvokeAI]::INFO --> NSFW checker initialized\u001b[0m\n",
            "\u001b[38;20m[2023-11-05 08:06:50,254]::[uvicorn.access]::INFO --> 37.151.215.77:0 - \"GET /api/v1/app/config HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2023-11-05 08:06:50,257]::[uvicorn.access]::INFO --> 37.151.215.77:0 - \"GET /api/v1/models/?base_models=sd-1&base_models=sd-2&base_models=sdxl&model_type=main HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2023-11-05 08:06:50,257]::[uvicorn.access]::INFO --> 37.151.215.77:0 - \"GET /api/v1/models/?base_models=sd-1&base_models=sd-2&base_models=sdxl&model_type=onnx HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2023-11-05 08:06:50,258]::[uvicorn.access]::INFO --> 37.151.215.77:0 - \"GET /api/v1/models/?model_type=vae HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2023-11-05 08:06:50,262]::[uvicorn.access]::INFO --> 37.151.215.77:0 - \"GET /api/v1/models/?model_type=controlnet HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2023-11-05 08:06:50,264]::[uvicorn.error]::INFO --> ('37.151.215.77', 0) - \"WebSocket /socket.io/?EIO=4&transport=websocket&sid=QIozJaB2EK4mlXjmAAAA\" [accepted]\u001b[0m\n",
            "\u001b[38;20m[2023-11-05 08:06:50,265]::[uvicorn.access]::INFO --> 37.151.215.77:0 - \"GET /assets/inter-latin-wght-normal-450f3ba4.woff2 HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2023-11-05 08:06:50,266]::[uvicorn.error]::INFO --> connection open\u001b[0m\n",
            "\u001b[38;20m[2023-11-05 08:06:50,486]::[uvicorn.access]::INFO --> 37.151.215.77:0 - \"GET /api/v1/boards/?all=true HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2023-11-05 08:06:50,488]::[uvicorn.access]::INFO --> 37.151.215.77:0 - \"GET /api/v1/images/?board_id=none&categories=control&categories=mask&categories=user&categories=other&is_intermediate=false&limit=0&offset=0 HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2023-11-05 08:06:50,603]::[uvicorn.access]::INFO --> 37.151.215.77:0 - \"GET /api/v1/images/?board_id=none&categories=general&is_intermediate=false&limit=100&offset=0 HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2023-11-05 08:06:50,604]::[uvicorn.access]::INFO --> 37.151.215.77:0 - \"GET /api/v1/models/?model_type=lora HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2023-11-05 08:06:50,605]::[uvicorn.access]::INFO --> 37.151.215.77:0 - \"GET /api/v1/images/?board_id=none&categories=general&is_intermediate=false&limit=0&offset=0 HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2023-11-05 08:06:50,691]::[uvicorn.access]::INFO --> 37.151.215.77:0 - \"POST /socket.io/?EIO=4&transport=polling&t=OkUXGhL&sid=QIozJaB2EK4mlXjmAAAA HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2023-11-05 08:06:50,691]::[uvicorn.access]::INFO --> 37.151.215.77:0 - \"GET /socket.io/?EIO=4&transport=polling&t=OkUXGhO&sid=QIozJaB2EK4mlXjmAAAA HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2023-11-05 08:06:53,179]::[uvicorn.access]::INFO --> 37.151.215.77:0 - \"GET /openapi.json HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2023-11-05 08:06:53,183]::[uvicorn.access]::INFO --> 37.151.215.77:0 - \"GET /api/v1/models/?model_type=embedding HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2023-11-05 08:06:53,186]::[uvicorn.access]::INFO --> 37.151.215.77:0 - \"GET /api/v1/models/?base_models=sd-1&base_models=sd-2&base_models=sdxl&model_type=main HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2023-11-05 08:06:53,186]::[uvicorn.access]::INFO --> 37.151.215.77:0 - \"GET /api/v1/models/?model_type=lora HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2023-11-05 08:06:53,188]::[uvicorn.access]::INFO --> 37.151.215.77:0 - \"GET /api/v1/models/?model_type=controlnet HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2023-11-05 08:06:53,189]::[uvicorn.access]::INFO --> 37.151.215.77:0 - \"GET /api/v1/models/?model_type=vae HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2023-11-05 08:06:53,873]::[uvicorn.access]::INFO --> 37.151.215.77:0 - \"GET /api/v1/app/version HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2023-11-05 08:06:53,874]::[uvicorn.access]::INFO --> 37.151.215.77:0 - \"GET /api/v1/app/config HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2023-11-05 08:07:26,352]::[uvicorn.access]::INFO --> 37.151.215.77:0 - \"POST /api/v1/sessions/ HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2023-11-05 08:07:26,581]::[uvicorn.access]::INFO --> 37.151.215.77:0 - \"PUT /api/v1/sessions/1db23caf-c0e4-4fae-bba5-ccd2e6fffdbd/invoke?all=true HTTP/1.1\" 202\u001b[0m\n",
            "\u001b[38;20m[2023-11-05 08:07:26,660]::[InvokeAI]::INFO --> Converting /content/db/models/sd-1/main/model.safetensors to diffusers format\u001b[0m\n",
            "\u001b[38;20m[2023-11-05 08:07:46,646]::[InvokeAI]::INFO --> Loading model /content/db/models/.cache/40c5bb4fa32829427d82ee66a4dcccdc, type sd-1:main:tokenizer\u001b[0m\n",
            "\u001b[38;20m[2023-11-05 08:07:47,607]::[InvokeAI]::INFO --> Loading model /content/db/models/.cache/40c5bb4fa32829427d82ee66a4dcccdc, type sd-1:main:text_encoder\u001b[0m\n",
            "\u001b[38;20m[2023-11-05 08:08:08,017]::[InvokeAI]::INFO --> Loading model /content/db/models/.cache/40c5bb4fa32829427d82ee66a4dcccdc, type sd-1:main:unet\u001b[0m\n",
            "\u001b[38;20m[2023-11-05 08:08:13,427]::[InvokeAI]::INFO --> Loading model /content/db/models/.cache/40c5bb4fa32829427d82ee66a4dcccdc, type sd-1:main:scheduler\u001b[0m\n",
            "100% 50/50 [00:15<00:00,  3.22it/s]\n",
            "\u001b[38;20m[2023-11-05 08:08:30,211]::[InvokeAI]::INFO --> Loading model /content/db/models/.cache/40c5bb4fa32829427d82ee66a4dcccdc, type sd-1:main:vae\u001b[0m\n",
            "\u001b[38;20m[2023-11-05 08:08:35,585]::[InvokeAI]::INFO --> Graph stats: 1db23caf-c0e4-4fae-bba5-ccd2e6fffdbd\u001b[0m\n",
            "\u001b[38;20m[2023-11-05 08:08:35,585]::[InvokeAI]::INFO -->                           Node   Calls  Seconds  VRAM Used\u001b[0m\n",
            "\u001b[38;20m[2023-11-05 08:08:35,585]::[InvokeAI]::INFO -->              main_model_loader     1     0.012s     0.000G\u001b[0m\n",
            "\u001b[38;20m[2023-11-05 08:08:35,586]::[InvokeAI]::INFO -->                      clip_skip     1     0.013s     0.000G\u001b[0m\n",
            "\u001b[38;20m[2023-11-05 08:08:35,586]::[InvokeAI]::INFO -->                         compel     2    41.189s     0.246G\u001b[0m\n",
            "\u001b[38;20m[2023-11-05 08:08:35,587]::[InvokeAI]::INFO -->                       rand_int     1     0.012s     0.244G\u001b[0m\n",
            "\u001b[38;20m[2023-11-05 08:08:35,587]::[InvokeAI]::INFO -->                  range_of_size     1     0.012s     0.244G\u001b[0m\n",
            "\u001b[38;20m[2023-11-05 08:08:35,587]::[InvokeAI]::INFO -->                        iterate     1     0.012s     0.244G\u001b[0m\n",
            "\u001b[38;20m[2023-11-05 08:08:35,588]::[InvokeAI]::INFO -->                          noise     1     0.019s     0.244G\u001b[0m\n",
            "\u001b[38;20m[2023-11-05 08:08:35,588]::[InvokeAI]::INFO -->                denoise_latents     1    22.138s     1.986G\u001b[0m\n",
            "\u001b[38;20m[2023-11-05 08:08:35,588]::[InvokeAI]::INFO -->           metadata_accumulator     1     0.013s     1.858G\u001b[0m\n",
            "\u001b[38;20m[2023-11-05 08:08:35,589]::[InvokeAI]::INFO -->                            l2i     1     5.372s     1.858G\u001b[0m\n",
            "\u001b[38;20m[2023-11-05 08:08:35,589]::[InvokeAI]::INFO --> TOTAL GRAPH EXECUTION TIME:   68.791s\u001b[0m\n",
            "\u001b[38;20m[2023-11-05 08:08:35,589]::[InvokeAI]::INFO --> RAM used by InvokeAI process: 8.46G (+1.820G)\u001b[0m\n",
            "\u001b[38;20m[2023-11-05 08:08:35,590]::[InvokeAI]::INFO --> RAM used to load models: 1.99G\u001b[0m\n",
            "\u001b[38;20m[2023-11-05 08:08:35,590]::[InvokeAI]::INFO --> VRAM in use: 0.303G\u001b[0m\n",
            "\u001b[38;20m[2023-11-05 08:08:35,591]::[InvokeAI]::INFO --> RAM cache statistics:\u001b[0m\n",
            "\u001b[38;20m[2023-11-05 08:08:35,591]::[InvokeAI]::INFO -->    Model cache hits: 2\u001b[0m\n",
            "\u001b[38;20m[2023-11-05 08:08:35,591]::[InvokeAI]::INFO -->    Model cache misses: 5\u001b[0m\n",
            "\u001b[38;20m[2023-11-05 08:08:35,592]::[InvokeAI]::INFO -->    Models cached: 5\u001b[0m\n",
            "\u001b[38;20m[2023-11-05 08:08:35,592]::[InvokeAI]::INFO -->    Models cleared from cache: 0\u001b[0m\n",
            "\u001b[38;20m[2023-11-05 08:08:35,592]::[InvokeAI]::INFO -->    Cache high water mark: 1.99/6.00G\u001b[0m\n",
            "\u001b[38;20m[2023-11-05 08:08:35,979]::[uvicorn.access]::INFO --> 37.151.215.77:0 - \"GET /api/v1/images/i/5b8da24a-a154-4f53-ae19-9614bbbf9371.png HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2023-11-05 08:08:36,285]::[uvicorn.access]::INFO --> 37.151.215.77:0 - \"GET /api/v1/images/?board_id=none&categories=general&is_intermediate=false&limit=0&offset=0 HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2023-11-05 08:08:36,399]::[uvicorn.access]::INFO --> 37.151.215.77:0 - \"GET /api/v1/images/?board_id=none&categories=control&categories=mask&categories=user&categories=other&is_intermediate=false&limit=0&offset=0 HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2023-11-05 08:08:36,401]::[uvicorn.access]::INFO --> 37.151.215.77:0 - \"GET /api/v1/images/i/5b8da24a-a154-4f53-ae19-9614bbbf9371.png/full HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2023-11-05 08:08:36,407]::[uvicorn.access]::INFO --> 37.151.215.77:0 - \"GET /api/v1/images/i/5b8da24a-a154-4f53-ae19-9614bbbf9371.png/thumbnail HTTP/1.1\" 200\u001b[0m\n",
            "\u001b[38;20m[2023-11-05 08:08:50,587]::[uvicorn.error]::INFO --> connection closed\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "#@markdown # **STEP 3**\n",
        "#@markdown ## Run StableDiffusion InvokeAI\n",
        "\n",
        "import os\n",
        "import shlex\n",
        "import subprocess\n",
        "from pathlib import Path\n",
        "from typing import Union\n",
        "clear_output()\n",
        "\n",
        "\n",
        "id_rsa_file = \"/content/InvokeAI/id_rsa\"\n",
        "id_rsa_pub_file = \"/content/InvokeAI/id_rsa.pub\"\n",
        "if os.path.exists(id_rsa_file):\n",
        "    os.remove(id_rsa_file)\n",
        "if os.path.exists(id_rsa_pub_file):\n",
        "    os.remove(id_rsa_pub_file)\n",
        "clear_output()\n",
        "\n",
        "def gen_key(path: Union[str, Path]) -> None:\n",
        "    path = Path(path)\n",
        "    arg_string = f'ssh-keygen -t rsa -b 4096 -N \"\" -q -f {path.as_posix()}'\n",
        "    args = shlex.split(arg_string)\n",
        "    subprocess.run(args, check=True)\n",
        "    path.chmod(0o600)\n",
        "\n",
        "ssh_name = \"id_rsa\"\n",
        "ssh_path = Path(os.path.dirname(os.getcwd())) / ssh_name\n",
        "gen_key(ssh_path)\n",
        "clear_output()\n",
        "\n",
        "import threading\n",
        "def tunnel():\n",
        "  !ssh -R 80:127.0.0.1:9090 -o StrictHostKeyChecking=no -i /content/id_rsa remote.moe\n",
        "threading.Thread(target=tunnel, daemon=True).start()\n",
        "\n",
        "%cd /content/InvokeAI/\n",
        "!python /content/InvokeAI/scripts/invokeai-web.py --root /content/db"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}